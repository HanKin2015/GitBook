# 显卡相关知识

## 1、GRID简介
GRID——NVIDIA的"云"

　　跟Shield一样，GRID的基本结构也不算不复杂，我们不仅熟悉而且甚至可以说是经常见到。GRID的基本结构就是一个由刀片服务器构成的机架，从单纯意义来讲它甚至可以说毫无新意可言。但当我们触及到GRID的细节之后，GRID就显得不那么“普通”了。

10年后显卡将消亡? GRID架构及前景解析 
NVIDIA VGX Hypervisor 

　　GRID的核心构筑在全新的硬件虚拟化技术——NVIDIA VGX Hypervisor 之上，与传统的刀片服务器不同，GRID的单运算节点由非CPU部分所组成。在每个节点也就是我们通俗理解的每个GRID的“刀片”内，NVIDIA都配置了用于直接处理任务的Tesla K10加速卡，或者我们可以干脆认为每一个节点内都被塞入了开放全部特性的GeForce GTX 690。之所以说是“开放了全部特性的GTX690”，是因为每个Tesla K10都可以以虚拟化硬件的形式同时处理8个并行的渲染任务请求，这让每一个节点都拥有了能够同时面对复数用户节点任务需求的能力。


NVIDIA于2020年7月发布了最新版本虚拟GPU软件vGPU 11.0，为全球数百万专业人士提供助力。这款软件能够支持更多工作负载，同时添加了能够提高IT管理员工作效率的功能。

虚拟图形处理单元（vGPU）是在虚拟桌面上渲染图形的一个组件。

如果不需要vGPU进行大型图形处理的应用程序，那么你的虚拟化环境就不需要vGPU。但是，如果有员工需要CAD或者3D等渲染软件以及vGPU处理图形的能力，那么选择正确的vGPU就相当重要了。


## 2、英伟达显卡，NVFBC捕获功能
直接从显卡的缓冲录制，屏幕上显示什么就录什么。如果用窗口模式玩游戏的话，就不只是录制游戏了。会连桌面上其他的东西都录进去

## 3、适配器(adapter/adaptor)
适配器是一个接口转换器，它可以是一个独立的硬件接口设备，允许硬件或电子接口与其它硬件或电子接口相连，也可以是信息接口。比如：电源适配器、三角架基座转接部件、USB与串口的转接设备等。

## 4、fence机制分析
 在任何一个系统中，无可避免的都会跟各种buffers打交道，最经典的模式就是消费-生产者模式，一个独立的buffer在它们之间的交换等操作都需要一个机制来控制每个buffer的“生命周期”，即ALLOCATION 和 RELEASE ，此外还要考虑到同步性问题，什么时候可以read buffer和write buffer都需要听从调遣。

  在android中的fence就是这样一个为了解决同步性而出现的机制。首先从fence的语义角度来分析一下它的基本原理：

Fence即栅栏，栅栏的角色与它的名字非常类似.一组线程可以使用栅栏来集体进行相互同步;在本质上,每个线程在到达某种周知的状态时调用栅栏的wait()方法,阻塞起来,以等待其它所有参与线程调用wait()方法表明它们也到达了这个状态.一旦所有的线程都到达栅栏,它们就会集体解除阻塞,并一起继续执行;引起程序调用栅栏的wait()方法进行阻塞的那个状态叫做栅栏状态。

接下来分析fence在android中的应用，这里主要涉及SurfaceFlinger中绘制buffer及显示中的相关方面。

确切的说fence在producer和consumer对buffer处理的过程中是如何协调他们同步的工作，从而保证buffer内容的准确性，而不会被篡改。

## 5、HDFS
HDFS（Hadoop Distributed File System）是一个分布式文件存储系统，几乎是离线存储领域的标准解决方案（有能力自研的大厂列外），业内应用非常广泛。

## 6、CPU 与 GPU 到底有什么区别
我们可以简单地将 CPU 理解为学识渊博的教授，什么都精通，而 GPU 则是一堆小学生，只会简单的算数运算，可即使教授再神通广大，也不能一秒钟内计算出 500 次加减法，因此对简单重复的计算来说，单单一个教授敌不过数量众多的小学生，在进行简单的算数运算这件事上，500 个小学生（并发）可以轻而易举打败教授。

因此我们可以看到，CPU 和 GPU 的最大不同在于架构，CPU 适用于广泛的应用场景（学识渊博），可以执行任意程序，而 GPU 则专为多任务而生，并发能力强，具体来讲就是多核，一般的 CPU 有 2 核、4 核、8 核等，而 GPU 则可能会有成百上千核。

只不过 CPU 中每个核的能力好比教授，而 GPU 的每个核的能力好比一个小学生。

我们需要为每个像素进行计算，而且是相同的运算，就好比刚才例子中的小学生计算加减法一样，注意，对于屏幕来说一般会有上百万个像素，如果我们要串行地为每一个像素进行运算效率就太低了，因此我们可以让 GPU 中的每一个核心去为相应的像素进行计算，由于 GPU 中有很多核心，因此并行计算可以大幅提高速度。

对 CPU 来说，不同的核心可以执行不同的机器指令，coreA 在运行 word 线程的同时 coreB 上可以运行浏览器线程，这就是所谓的多指令多数据，MIMD，(Multiple Instruction, Multiple Data)。
而 GPU 则不同，GPU 上的这些核心必须整齐划一地运行相同的机器指令，只是可以操作不同的数据，这就好比这些小学生在某个时刻必须都进行加法计算，不同的地方在于有的小学生可能需要计算 1+1，有的要计算 2+6 等等，变化的地方仅在于操作数，这就是所谓的单指令多数据，SIMD，(Single Instruction, Multiple Data)。

比较适合 GPU 的计算场景是这样的：1)计算简单；2）重复计算。
如果你的计算场景和这里的图像渲染相似，那么使用 GPU 就很合理了。
因此对于图形图像计算、天气预报以及神经网络等都适用于 GPU，哦对了，GPU 还适合用来挖矿。




